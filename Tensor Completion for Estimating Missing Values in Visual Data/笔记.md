# 张量补全的挑战
张量补全的一个主要难点是如何定义张量的秩和迹范数，这两个概念在矩阵情况下有明确的含义和计算方法，但是在张量情况下并没有统一的定义和算法。文档提出了一种基于矩阵迹范数的张量迹范数的定义，以及相应的张量补全的凸优化模型。
# 张量补全的算法
本文提出了三种算法来求解张量补全的优化模型，分别是SiLRTC、FaLRTC和HaLRTC。这三种算法都是基于块坐标下降的思想，但是采用了不同的技巧来加速收敛和提高精度。本文还给出了这三种算法的理论分析和实验结果，与一些启发式的算法进行了比较。本文还展示了一些张量补全的潜在应用，如图像修复、视频压缩和BRDF数据估计。
# 符号定义
**矩阵(Matrix)**：**X**\
**条目(Entries)**: $x_{ij}$\
**向量(Vector)**: $\sum(X)$是一个向量，由X的奇异值按降序排列组成。\
**最大的奇异值(Largest Singular Value)**: $\delta_i(X)$表示第i个最大的奇异值。\
**弗罗贝尼乌斯范数（Frobenius Norm）**：矩阵X的弗罗贝尼乌斯范数定义为![1700227544301](https://github.com/HDZ12/SCI-programmming/assets/99587726/e63637d3-be4b-4765-8697-ad8424d56732)弗罗贝尼乌斯范数（Frobenius Norm）是一种用于衡量矩阵大小的范数。对于一个m×n的矩阵A，其弗罗贝尼乌斯范数定义为矩阵A中所有元素的平方和的平方根\
**谱范数(Spectral Norm)**：![1700227899894](https://github.com/HDZ12/SCI-programmming/assets/99587726/af211ae8-a486-4876-aec0-29ef5015bb57)谱范数（Spectral Norm）是一种用于衡量矩阵大小的范数。对于一个m×n的矩阵A，其谱范数定义为矩阵A的所有奇异值的最大值,其中，δ1​(A)表示矩阵A的最大奇异值。奇异值是矩阵的一种重要特性，它反映了矩阵在各个方向上的“拉伸”或“压缩”程度。谱范数因此可以被视为矩阵的一种“最大拉伸因子”。\
**迹范数（Trace Norm)**:![1700228163887](https://github.com/HDZ12/SCI-programmming/assets/99587726/d439c77b-d1f0-438f-bf8f-35d6928bd211)迹范数（Trace Norm）也被称为核范数，是一种用于衡量矩阵大小的范数。对于一个m×n的矩阵A，其迹范数定义为矩阵A的所有奇异值的和，其中，δi​(A)表示矩阵A的第i个奇异值。奇异值是矩阵的一种重要特性，它反映了矩阵在各个方向上的“拉伸”或“压缩”程度。因此，迹范数可以被视为矩阵的一种“总拉伸因子”。\
 **奇异值分解（Singular Value Decomposition）**：![1700228331724](https://github.com/HDZ12/SCI-programmming/assets/99587726/46b7e555-f264-4244-b2af-0bcb962f7595)奇异值分解（Singular Value Decomposition，简称SVD）是一种在机器学习领域广泛应用的算法，它不仅可以用于降维算法中的特征分解，还可以用于推荐系统，以及自然语言处理等领域。奇异值分解将任何给定矩阵分解为三个矩阵的乘积：其中，A是我们要分解的m×n矩阵，U是一个m×m的矩阵，Σ是一个m×n的矩阵，除了主对角线上的元素以外全为0，主对角线上的每个元素都称为奇异值，V是一个n×n的矩阵1。U和V都是酉矩阵，即满足U^T·U=I，V^T·V=I。奇异值分解的一个重要性质是，我们可以用最大的k个的奇异值和对应的左右奇异向量来近似描述矩阵。也就是说，我们可以将一个大的矩阵A用三个小的矩阵​来表示，相当于PCA降维。\
 **收缩算子( shrinkage operator)**:![1700231065608](https://github.com/HDZ12/SCI-programmming/assets/99587726/c243fcdb-5df0-49ee-9bab-011028572a34)其中，U、Σ和V是矩阵X的奇异值分解，Στ​是将Σ中的每个奇异值通过某种函数（通常是硬阈值函数或软阈值函数）映射得到的矩阵。这个运算符的作用是去除矩阵X的奇异值分解中的小奇异值，从而得到一个低秩的近似。在处理低秩矩阵或张量的问题.![1700231336248](https://github.com/HDZ12/SCI-programmming/assets/99587726/3936f621-ab0b-4520-ade7-2aff3480dc49)这个运算符的作用是去除矩阵X的奇异值分解中的小奇异值，从而得到一个低秩的近似。\
 **截断操作(truncate operation)**:![1700231446769](https://github.com/HDZ12/SCI-programmming/assets/99587726/21e70d52-8b4b-4c7f-ba4e-8e56b33a364c)
![1700231487036](https://github.com/HDZ12/SCI-programmming/assets/99587726/6fb375fc-cb35-45e3-ad42-c2e4fd5e856f)这个运算符的作用是将矩阵X的奇异值分解中的大奇异值截断为τ，从而得到一个对角线元素不超过τ的矩阵。\
**索引集**：![1700231709862](https://github.com/HDZ12/SCI-programmming/assets/99587726/c606c8ba-8a7a-46c6-ac8a-a04929884b04)一个名为XΔ​的矩阵。这里，Δ是一个索引集，XΔ​表示从矩阵X中复制Δ集合中的条目，并让剩余的条目为“0”。\
**n阶张量**：X∈R^{I1​×I2​×…×In}​。它的元素被表示为x_{i1​,…,in}​​，其中1≤i_k​≤I_k​，1≤k≤n。\
**展开操作(unflod)**:![1700232051569](https://github.com/HDZ12/SCI-programmming/assets/99587726/b98121ca-b81c-4136-b6e9-ddb5985419e0)将一个张量展开成一个矩阵。沿着张量X的第k个模式(K阶)(第k个维度作为行索引，将其他所有维度一起作为列索引)的展开操作\
**折叠操作(fold)**:![1700232352745](https://github.com/HDZ12/SCI-programmming/assets/99587726/d03553b2-1dc4-4d7a-95d7-7730690f6998)与展开操作相反的是折叠操作\
**张量的弗罗贝尼乌斯范数定义为**:![1700232534887](https://github.com/HDZ12/SCI-programmming/assets/99587726/b88bc5c1-28ea-4af5-a516-c06f178daeff)张量X的弗罗贝尼乌斯范数等于张量X沿第k个模式展开后得到的矩阵的弗罗贝尼乌斯范数。这是因为弗罗贝尼乌斯范数是基于元素的，不受张量展开的影响。 \
**使用非负上标数字来表示迭代指数**：x^{k} 负上标数字表示幂。
# 张量补全的公式
本文介绍了一个凸模型和三个启发式算法
## 低秩矩阵补全算法
在这个问题中，给定一个矩阵M的一部分元素，目标是找到一个矩阵X，使得X的秩尽可能小，同时X的给定元素与M的相应元素相同。这个问题是一个非凸优化问题，因为秩函数是非凸的。一个常见的方法是使用矩阵的迹范数来近似矩阵的秩。迹范数的优点是它是矩阵秩的最紧凸包络。这就导致了矩阵补全的一个凸优化问题。
![1700270918240](https://github.com/HDZ12/SCI-programmming/assets/99587726/42942d2f-32c8-4c48-af34-48420bb1bb9d)![1700271004470](https://github.com/HDZ12/SCI-programmming/assets/99587726/82dd5612-1fe0-4444-9034-9b82184e59f6)
## 推广到张量补全
张量是矩阵概念的推广。我们通过解决以下优化问题将矩阵（即2模或2阶张量）的补全算法推广到更高阶的张量：最小化张量的迹范数，同时满足张量的某些元素等于给定值。这个问题的难点在于如何定义张量的迹范数。作者提出了一种定义，即张量的迹范数是所有沿各模式展开的矩阵的迹范数的凸组合。当模式数n等于2（即矩阵情况）时，张量的迹范数的定义与矩阵情况一致，因为矩阵的迹范数等于其转置的迹范数。在这个定义下，优化问题可以写成最小化张量的迹范数，同时满足张量的某些元素等于给定值。![1700271877522](https://github.com/HDZ12/SCI-programmming/assets/99587726/7c905aec-6ac2-4200-b6a6-ba4ca0080dd5)
## 三个启发式算法
### Tucker模型
![1700272128194](https://github.com/HDZ12/SCI-programmming/assets/99587726/a0100d36-6593-4e22-8575-db294b63e2b4)Tucker模型是一种自然的方法，用于将张量分解应用于张量补全问题。在这个问题中，我们需要最小化张量X和C、U1，…，Un的函数，同时满足张量X的某些元素等于给定值。\
**张量分解**：![1700272209321](https://github.com/HDZ12/SCI-programmming/assets/99587726/73b7daef-c2c3-45bf-bf0d-34886d54f4f8)（张量-矩阵乘法）是基于Tucker模型的张量分解，其中Ui是一个矩阵，C是一个核心张量，T和X是n模张量，每个模式的大小相同。\
**优化方法**：块坐标下降法，通过迭代优化两个块X和C、U1，…，Un，同时固定另一个。X可以通过让![1700272735170](https://github.com/HDZ12/SCI-programmming/assets/99587726/927c6d0a-56ba-49ac-9003-f5b81758073c)来计算。C、U1，…，Un可以通过任何基于Tucker模型的现有张量分解算法来计算。这个过程会一直重复，直到满足某个停止准则，例如达到最大迭代次数，或者X和C、U1，…，Un的更新量小于某个阈值。\
### Parafac模型
![1700273290602](https://github.com/HDZ12/SCI-programmming/assets/99587726/fb344ba0-9598-46c5-8fcd-fa80483b9349)Parafac模型是一种自然的方法，用于将张量分解应用于张量补全问题。在这个问题中，我们需要最小化张量X和U1，U2，…，Un的函数，同时满足张量X的某些元素等于给定值。\
**张量分解**：![1700279550266](https://github.com/HDZ12/SCI-programmming/assets/99587726/b08376fa-a4b4-49f7-aaea-2055e252ae04)（矩阵外积）\
**优化方法**：块坐标下降法
### SVD模型
![1700273561555](https://github.com/HDZ12/SCI-programmming/assets/99587726/0fd44702-435c-497c-b914-58354438e7d8)SVD模型是另一种方法，它将张量视为多个矩阵，并强制每个模式下展开的矩阵为低秩。在这个问题中，我们需要最小化张量X和M1，M2，…，Mn的函数，同时满足张量X的某些元素等于给定值。







 



