# 张量补全的挑战
张量补全的一个主要难点是如何定义张量的秩和迹范数，这两个概念在矩阵情况下有明确的含义和计算方法，但是在张量情况下并没有统一的定义和算法。文档提出了一种基于矩阵迹范数的张量迹范数的定义，以及相应的张量补全的凸优化模型。
# 张量补全的算法
本文提出了三种算法来求解张量补全的优化模型，分别是SiLRTC、FaLRTC和HaLRTC。这三种算法都是基于块坐标下降的思想，但是采用了不同的技巧来加速收敛和提高精度。本文还给出了这三种算法的理论分析和实验结果，与一些启发式的算法进行了比较。本文还展示了一些张量补全的潜在应用，如图像修复、视频压缩和BRDF数据估计。
# 符号定义
**矩阵(Matrix)**：**X**\
**条目(Entries)**: $x_{ij}$\
**向量(Vector)**: $\sum(X)$是一个向量，由X的奇异值按降序排列组成。\
**最大的奇异值(Largest Singular Value)**: $\delta_i(X)$表示第i个最大的奇异值。
**弗罗贝尼乌斯范数（Frobenius Norm）**：矩阵X的弗罗贝尼乌斯范数定义为![1700227544301](https://github.com/HDZ12/SCI-programmming/assets/99587726/e63637d3-be4b-4765-8697-ad8424d56732)弗罗贝尼乌斯范数（Frobenius Norm）是一种用于衡量矩阵大小的范数。对于一个m×n的矩阵A，其弗罗贝尼乌斯范数定义为矩阵A中所有元素的平方和的平方根\
**谱范数(Spectral Norm)**：![1700227899894](https://github.com/HDZ12/SCI-programmming/assets/99587726/af211ae8-a486-4876-aec0-29ef5015bb57)谱范数（Spectral Norm）是一种用于衡量矩阵大小的范数。对于一个m×n的矩阵A，其谱范数定义为矩阵A的所有奇异值的最大值,其中，δ1​(A)表示矩阵A的最大奇异值。奇异值是矩阵的一种重要特性，它反映了矩阵在各个方向上的“拉伸”或“压缩”程度。谱范数因此可以被视为矩阵的一种“最大拉伸因子”。\
**迹范数（Trace Norm)**:![1700228163887](https://github.com/HDZ12/SCI-programmming/assets/99587726/d439c77b-d1f0-438f-bf8f-35d6928bd211)迹范数（Trace Norm）也被称为核范数，是一种用于衡量矩阵大小的范数。对于一个m×n的矩阵A，其迹范数定义为矩阵A的所有奇异值的和，其中，δi​(A)表示矩阵A的第i个奇异值。奇异值是矩阵的一种重要特性，它反映了矩阵在各个方向上的“拉伸”或“压缩”程度。因此，迹范数可以被视为矩阵的一种“总拉伸因子”。\
 **奇异值分解（Singular Value Decomposition）**：![1700228331724](https://github.com/HDZ12/SCI-programmming/assets/99587726/46b7e555-f264-4244-b2af-0bcb962f7595)奇异值分解（Singular Value Decomposition，简称SVD）是一种在机器学习领域广泛应用的算法，它不仅可以用于降维算法中的特征分解，还可以用于推荐系统，以及自然语言处理等领域1。奇异值分解将任何给定矩阵分解为三个矩阵的乘积2：其中，A是我们要分解的m×n矩阵，U是一个m×m的矩阵，Σ是一个m×n的矩阵，除了主对角线上的元素以外全为0，主对角线上的每个元素都称为奇异值，V是一个n×n的矩阵1。U和V都是酉矩阵，即满足$U^{T}U=I$，VTV=I1。



